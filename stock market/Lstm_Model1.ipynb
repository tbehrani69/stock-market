{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b536462-3b58-45f1-9a96-7452838e4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6183abf3-a60e-4d59-909e-f39a5e863d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch historical stock data\n",
    "def fetch_stock_data(symbol, start_date, end_date):\n",
    "    stock = yf.Ticker(symbol)\n",
    "    df = stock.history(start=start_date, end=end_date)\n",
    "    return df[['Open', 'High', 'Low', 'Close', 'Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78507337-273e-4e94-86cb-92c0512f5472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train an LSTM model for stock price prediction\n",
    "def create_lstm_model(data, time_steps, future_days):\n",
    "    # Normalize the data to a range between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    # Prepare the data for LSTM with the given time steps\n",
    "    X, y = [], []\n",
    "    for i in range(time_steps, len(scaled_data) - future_days + 1):\n",
    "        X.append(scaled_data[i - time_steps:i])\n",
    "        y.append(scaled_data[i:i + future_days, 3])  # 3 corresponds to 'Close' column\n",
    "\n",
    "    # Convert to numpy arrays for model training\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    n_features = X.shape[2]\n",
    "\n",
    "    # Define the LSTM model structure\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(time_steps, n_features)),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dense(future_days)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X, y, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
    "    return model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131ba60d-efe2-4aeb-b2f2-d27bc5be63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict future prices using the trained LSTM model\n",
    "def predict_future_prices(model, scaler, last_sequence, future_days):\n",
    "    last_sequence_scaled = scaler.transform(last_sequence)  # Scale the last sequence of input data\n",
    "    predicted_scaled = model.predict(np.array([last_sequence_scaled]))  # Predict future prices\n",
    "\n",
    "    # Reverse the scaling to get actual price values\n",
    "    predicted = scaler.inverse_transform(np.column_stack((predicted_scaled[0], np.zeros((future_days, 4))))) \n",
    "    return predicted[:, 0]  # Return only the 'Close' price predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f09e852b-5605-47eb-93f4-66a9066a7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the selected stock and generate future price predictions\n",
    "def prepare_stock_data(symbol):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365*5)  # Use 5 years of historical data\n",
    "    data = fetch_stock_data(symbol, start_date, end_date)\n",
    "    time_steps = 60  # Days of past data used to predict the future\n",
    "    future_days = 15  # Predict prices for the next 15 days\n",
    "\n",
    "    # Train the model and get the scaler\n",
    "    model, scaler = create_lstm_model(data, time_steps, future_days)\n",
    "\n",
    "    # Prepare the last 'time_steps' days of data for prediction\n",
    "    last_sequence = data.iloc[-time_steps:].values\n",
    "    future_prices = predict_future_prices(model, scaler, last_sequence, future_days)\n",
    "\n",
    "    # Generate future dates and create a DataFrame with predictions\n",
    "    future_dates = pd.date_range(start=end_date, periods=future_days)\n",
    "    future_df = pd.DataFrame({'Date': future_dates, 'Predicted_Close': future_prices})\n",
    "    \n",
    "    return data, future_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f9ce3a4-7bf6-47a1-aa28-231eca0462f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.1218 - val_loss: 0.0376\n",
      "Epoch 2/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0160\n",
      "Epoch 3/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0025 - val_loss: 0.0115\n",
      "Epoch 4/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0026 - val_loss: 0.0172\n",
      "Epoch 5/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0023 - val_loss: 0.0118\n",
      "Epoch 6/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0023 - val_loss: 0.0108\n",
      "Epoch 7/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0023 - val_loss: 0.0137\n",
      "Epoch 8/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0161\n",
      "Epoch 9/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0023 - val_loss: 0.0103\n",
      "Epoch 10/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0022 - val_loss: 0.0072\n",
      "Epoch 11/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 12/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0022 - val_loss: 0.0115\n",
      "Epoch 13/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0133\n",
      "Epoch 14/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0021 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 16/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0020 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0021 - val_loss: 0.0166\n",
      "Epoch 18/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0019 - val_loss: 0.0153\n",
      "Epoch 19/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0022 - val_loss: 0.0079\n",
      "Epoch 20/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0021 - val_loss: 0.0102\n",
      "Epoch 21/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 22/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 23/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0018 - val_loss: 0.0085\n",
      "Epoch 24/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 25/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0018 - val_loss: 0.0151\n",
      "Epoch 26/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 27/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0018 - val_loss: 0.0084\n",
      "Epoch 28/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 29/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - val_loss: 0.0059\n",
      "Epoch 30/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - val_loss: 0.0072\n",
      "Epoch 31/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0017 - val_loss: 0.0098\n",
      "Epoch 32/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0017 - val_loss: 0.0114\n",
      "Epoch 33/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0128\n",
      "Epoch 34/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0018 - val_loss: 0.0100\n",
      "Epoch 35/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0017 - val_loss: 0.0071\n",
      "Epoch 36/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0020 - val_loss: 0.0083\n",
      "Epoch 37/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 38/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 39/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0017 - val_loss: 0.0070\n",
      "Epoch 40/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - val_loss: 0.0056\n",
      "Epoch 41/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0016 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0016 - val_loss: 0.0098\n",
      "Epoch 43/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0016 - val_loss: 0.0082\n",
      "Epoch 44/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 0.0100\n",
      "Epoch 45/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0103\n",
      "Epoch 46/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 0.0099\n",
      "Epoch 47/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 48/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0017 - val_loss: 0.0072\n",
      "Epoch 49/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0017 - val_loss: 0.0071\n",
      "Epoch 50/50\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0014 - val_loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
      "Historical data shape: (1258, 5)\n",
      "Future data shape: (15, 2)\n",
      "Future predicted prices:\n",
      "                         Date  Predicted_Close\n",
      "0  2024-11-16 04:25:10.636446       220.232273\n",
      "1  2024-11-17 04:25:10.636446       221.493210\n",
      "2  2024-11-18 04:25:10.636446       218.939624\n",
      "3  2024-11-19 04:25:10.636446       218.296850\n",
      "4  2024-11-20 04:25:10.636446       218.185498\n",
      "5  2024-11-21 04:25:10.636446       216.796238\n",
      "6  2024-11-22 04:25:10.636446       214.430621\n",
      "7  2024-11-23 04:25:10.636446       216.574415\n",
      "8  2024-11-24 04:25:10.636446       213.976688\n",
      "9  2024-11-25 04:25:10.636446       213.733849\n",
      "10 2024-11-26 04:25:10.636446       215.226552\n",
      "11 2024-11-27 04:25:10.636446       208.972818\n",
      "12 2024-11-28 04:25:10.636446       210.852468\n",
      "13 2024-11-29 04:25:10.636446       206.950200\n",
      "14 2024-11-30 04:25:10.636446       208.688680\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    symbol = \"AAPL\"  # Example stock symbol\n",
    "    historical_data, future_data = prepare_stock_data(symbol)  # Fetch and predict\n",
    "\n",
    "    print(f\"Historical data shape: {historical_data.shape}\")\n",
    "    print(f\"Future data shape: {future_data.shape}\")\n",
    "    print(f\"Future predicted prices:\\n{future_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b36889-1e04-4a3b-9e56-c5273b0a3047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
